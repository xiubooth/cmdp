{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import animation\n",
    "import numpy as np\n",
    "import ray\n",
    "from ray.rllib.agents import ppo\n",
    "\n",
    "from mdps.cliff import ContextualCliff\n",
    "from utils.distributions import ConstantDistribution, ParticleDistribution, UniformDistribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# some utils used later\n",
    "\n",
    "def prepare_animation(bar_container_, context_history_):\n",
    "    \"\"\"Used for animated plotting sampling precedure\"\"\"\n",
    "    def animate(frame_number, data=context_history_):\n",
    "        # simulate new data coming in\n",
    "        x = data[frame_number][:, 1]\n",
    "        n, _ = np.histogram(x, HIST_BINS)\n",
    "        plt.title(f'{frame_number} posterior mean: {round(x.mean(), 5)}')\n",
    "        for count, rect in zip(n, bar_container_.patches):\n",
    "            rect.set_height(count)\n",
    "        return bar_container_.patches\n",
    "\n",
    "    return animate\n",
    "\n",
    "\n",
    "# collect expert rollout\n",
    "\n",
    "def get_rollouts(solver_, config):\n",
    "    \"\"\"Generate rollouts from a given solver and MDP(c)\"\"\"\n",
    "    env_ = ContextualCliff(config=config)\n",
    "    done_ = False\n",
    "    obs_ = env_.reset()\n",
    "    # run until episode ends\n",
    "    gt_obs_arr_ = None\n",
    "    gt_act_arr_ = None\n",
    "    while not done_:\n",
    "        action_ = solver_.compute_single_action(obs_)\n",
    "        obs_, _, done_, _ = env_.step(action_)\n",
    "        if gt_obs_arr_ is None:\n",
    "            gt_obs_arr_ = obs_\n",
    "            gt_act_arr_ = [action_]\n",
    "        else:\n",
    "            gt_obs_arr_ = np.vstack((gt_obs_arr_, obs_))\n",
    "            gt_act_arr_ += [action_]\n",
    "\n",
    "    gt_act_arr_ = np.array(gt_act_arr_)\n",
    "    return gt_obs_arr_, gt_act_arr_\n",
    "\n",
    "def plot_rollouts(gt_obs_arr_, gt_act_arr_):\n",
    "    \"\"\"Plot generated rollouts\"\"\"\n",
    "    fig_, ax_1 = plt.subplots()\n",
    "    fig_.set_size_inches(10, 6, forward=True)\n",
    "\n",
    "    x = np.arange(start=0, stop=gt_obs_arr_.shape[0])\n",
    "    ax_2 = ax_1.twinx()\n",
    "    ax_1.plot(x, gt_obs_arr_[:, 0], 'r-')\n",
    "    ax_2.plot(x, gt_act_arr_, 'b-', alpha=0.3)\n",
    "\n",
    "    ax_1.set_xlabel('time step')\n",
    "    ax_1.set_ylabel('Position (x)', color='r')\n",
    "    ax_2.set_ylabel('Action', color='b')\n",
    "    plt.title('sample observations and actions')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Contextual \"cliff\"\n",
    "\n",
    "This notebook studies using particle filtering to estimate the context parameters of a standard `Cliff` environment in `mdps.cliff`.\n",
    "\n",
    "The `Cliff` environment has a cart that chooses either to go left or right for a `step_size`. It starts at the `mid_point` of the `right_end` and the `left_end`, and it receives a reward proportional to the power (default set to 2) of its current location, `x`. If it \"falls off the cliff\" from the left or right end, however, it receives a highly negative reward and the episode ends. Also, there are noise and drift terms, and the state-transition equation of the position `x` is (where `action` is 0 or 1 for moving left or right):\n",
    "\\\n",
    "$x_{t+1} = N(0, \\text{noise}) - \\text{drift} * x + 2 * (\\text{action}-0.5) * \\text{stepsize}$\n",
    "\n",
    "Thus, the goal of the cart is to keep its position `x` as large as possible (i.e. close to the larger end) and in the meantime keep a distance to that end to prevent accidentally falling off due to the transition noise.\n",
    "\n",
    "The context params are: `(left_bound, right_bound, pow, step_size, noise, drift)`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Set target\n",
    "\n",
    "We first create a target config, $c$. This will be the $MDP(c)$ the expert uses to generate the observational data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# true (expert) context: (left_bound, right_bound, pow, step_size, noise, drift) =\n",
    "#                         [0.0, 3.0, 2.0, 0.05, 0.05, 0.0]\n",
    "c = {'context_distribution':\n",
    "         ConstantDistribution(dim=6,\n",
    "                              constant_vector=np.array([0.0, 2, 2, 0.05, 0.05, 0.0]))}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "First, train an expert that masters this context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "ray.shutdown()\n",
    "ray.init()\n",
    "expert = ppo.PPOTrainer(env=ContextualCliff, config={\n",
    "    \"env_config\": c,\n",
    "    \"framework\": \"torch\",  # config to pass to env class\n",
    "})\n",
    "\n",
    "rews = []\n",
    "for eps in range(25):\n",
    "    res = expert.train()\n",
    "    if eps % 5 == 0:\n",
    "        print(eps, res['episode_reward_mean'])\n",
    "    rews += [res['episode_reward_mean']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# collect expert rollout\n",
    "gt_obs_arr, gt_act_arr = get_rollouts(expert, config=c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plot_rollouts(gt_obs_arr, gt_act_arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Exact context\n",
    "\n",
    "We first train a RL solver only on the correct context for particle filtering. We have already done this so we can directly use the expert solver."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# true (expert) context: (left_bound, right_bound, pow, step_size, noise, drift) =\n",
    "#                       [0.0, 3.0, 2.0, 0.025, 0.05, 0.0]\n",
    "\n",
    "N = 2000\n",
    "T = 100\n",
    "left_bound = np.ones((N,)) * 0.0\n",
    "pow = np.ones((N,)) * 2\n",
    "drift = np.random.normal(loc=0.00, scale=0.001, size=(N,))\n",
    "step_size = np.ones((N,)) * 0.025"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def filter_context(solver_,\n",
    "                   context_distribution_,\n",
    "                   gt_obs_arr_,\n",
    "                   T_,\n",
    "                   N_\n",
    "                   ):\n",
    "    state_arr_ = np.zeros((N_,))\n",
    "    action_arr_ = np.zeros((N_,))\n",
    "    context_history_ = []\n",
    "    for t_ in range(T_):\n",
    "        # we only use the first 5 steps of the cartpole steps to reduce effect of different episode lengths\n",
    "        qs_ = np.zeros((N_,))\n",
    "        for n_ in range(N_):\n",
    "            context_ = context_distribution_.particles[n_]\n",
    "            c_local_ = {'context_distribution':\n",
    "                           ConstantDistribution(dim=6,\n",
    "                                                constant_vector=context_)}\n",
    "            env_ = ContextualCliff(config=c_local_)\n",
    "            obs_ = env_.reset()\n",
    "            if t_ > 0:\n",
    "                env_.mdp.x = state_arr_[n_]\n",
    "                obs_ = np.concatenate((np.array([env_.mdp.x]), context_), axis=0).flatten()\n",
    "            action_ = solver_.compute_single_action(obs_)\n",
    "            obs_, _, done_, _ = env_.step(action_)\n",
    "            # estimate likelihood if r >= 1\n",
    "            if t_ >= 1:\n",
    "                q = env_.likelihood(gt_obs_arr_[t_ - 1], action_arr_[n_], obs_)\n",
    "                qs_[n_] = q\n",
    "            state_arr_[n_] = np.copy(env_.mdp.x)\n",
    "            action_arr_[n_] = action_\n",
    "        if t_ >= 1:\n",
    "            # truncated importance sampling; [https://arxiv.org/pdf/1905.09800.pdf]\n",
    "            qs_ = np.clip(qs_, 0, np.percentile(qs_, 90))\n",
    "            qs_ = qs_ / qs_.sum()\n",
    "            resample_index_ = context_distribution_.resample_particles_from_probability(p=qs_)\n",
    "            p_temp_ = context_distribution_.particles\n",
    "            p_noise_ = np.random.normal(loc=0, scale=p_temp_.std(axis=0), size=p_temp_.shape) * 0.05\n",
    "            context_distribution_.particles += p_noise_\n",
    "            state_arr_ = state_arr_[resample_index_]\n",
    "            action_arr_ = action_arr_[resample_index_]\n",
    "        if t_ % 10 == 0:\n",
    "            print(\"round\", t_, \"posterior mean\", context_distribution_.particles[:, 1].mean())\n",
    "        context_history_ += [context_distribution_.particles.copy()]\n",
    "    return context_history_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "right_bound = np.random.normal(loc=2.5, scale=0.5, size=(N,))\n",
    "noise = np.ones((N,)) * 0.05\n",
    "\n",
    "context_particles = np.abs(np.vstack((left_bound, right_bound, pow, step_size, noise, drift)).T)\n",
    "context_distribution = ParticleDistribution(dim=6, particles=context_particles, n_particles=N)\n",
    "\n",
    "context_history_exact = filter_context(expert,\n",
    "                                   context_distribution,\n",
    "                                   gt_obs_arr,\n",
    "                                   T,\n",
    "                                   N\n",
    "                                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "HIST_BINS = np.linspace(1, 3, 120)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "plt.axvline(x=2.0, alpha=0.3, color='black', linestyle='--')\n",
    "plt.legend(['ground truth: 2.0'])\n",
    "_, _, bar_container = ax.hist(context_history_exact[0][:, 1], HIST_BINS, lw=1,\n",
    "                              ec=\"cyan\", fc=\"blue\", alpha=0.5)\n",
    "ax.set_ylim(top=N / 4)  # set safe limit to ensure that all data is visible.\n",
    "\n",
    "ani = animation.FuncAnimation(fig, prepare_animation(bar_container, context_history_exact),\n",
    "                              len(context_history_exact),\n",
    "                              repeat=True, blit=False, interval=100, repeat_delay=500)\n",
    "prior_mean = 2.5\n",
    "posterior_mean = round(context_history_exact[-1][:, 1].mean(), 3)\n",
    "ani.save(f'prior_{prior_mean}_posterior{posterior_mean}.mp4', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "HIST_BINS = np.linspace(1, 4, 80)\n",
    "ax.hist(context_history_exact[0][:, 1], HIST_BINS, lw=1,\n",
    "        ec=\"blue\", fc=\"blue\", alpha=0.5)\n",
    "ax.hist(context_history_exact[-1][:, 1], HIST_BINS, lw=1,\n",
    "        ec=\"red\", fc=\"red\", alpha=0.5)\n",
    "plt.axvline(x=2, alpha=0.3, color='black', linestyle='--')\n",
    "plt.legend(['ground truth: 2.0', 'prior', 'posterior'])\n",
    "ax.set_ylim(top=N / 5)\n",
    "fig.set_size_inches(12, 8)\n",
    "plt.title('solver trained in exactly specified context')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# We reduce the right end from 2.0 to 1.5 and keep otherwise the same.\n",
    "c_mis = {'context_distribution':\n",
    "             ConstantDistribution(dim=5,\n",
    "                                  constant_vector=np.array([0.0, 1.5, 2.0, 0.025, 0.05, 0.0]))}\n",
    "\n",
    "ray.shutdown()\n",
    "ray.init()\n",
    "mis_solver = ppo.PPOTrainer(env=ContextualCliff, config={\n",
    "    \"env_config\": c_mis,\n",
    "    \"framework\": \"torch\",  # config to pass to env class\n",
    "})\n",
    "\n",
    "for eps in range(25):\n",
    "    res = mis_solver.train()\n",
    "    if eps % 5 == 0:\n",
    "        print(eps, res['episode_reward_mean'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "mis_obs_arr, mis_act_arr = get_rollouts(mis_solver, config=c)\n",
    "plot_rollouts(mis_obs_arr, mis_act_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# true (expert) context: (left_bound, right_bound, pow, step_size, noise, drift) =\n",
    "#                       [0.0, 3.0, 2.0, 0.025, 0.05, 0.0]\n",
    "\n",
    "right_bound = np.random.normal(loc=2.5, scale=0.5, size=(N,))\n",
    "noise = np.ones((N,)) * 0.05\n",
    "\n",
    "context_particles = np.abs(np.vstack((left_bound, right_bound, pow, step_size, noise, drift)).T)\n",
    "context_distribution = ParticleDistribution(dim=6, particles=context_particles, n_particles=N)\n",
    "\n",
    "context_history_mis = filter_context(mis_solver,\n",
    "                                       context_distribution,\n",
    "                                       gt_obs_arr,\n",
    "                                       T,\n",
    "                                       N\n",
    "                                       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "HIST_BINS = np.linspace(1, 5, 80)\n",
    "ax.hist(context_history_mis[0][:, 1], HIST_BINS, lw=1,\n",
    "        ec=\"blue\", fc=\"blue\", alpha=0.5)\n",
    "ax.hist(context_history_mis[-1][:, 1], HIST_BINS, lw=1,\n",
    "        ec=\"red\", fc=\"red\", alpha=0.5)\n",
    "plt.axvline(x=2, alpha=0.3, color='black', linestyle='--')\n",
    "plt.legend(['ground truth: 2.0', 'prior', 'posterior'])\n",
    "ax.set_ylim(top=N / 5)\n",
    "fig.set_size_inches(12, 8)\n",
    "plt.title('solver trained in mis-specified context')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Uniformly sampled context\n",
    "\n",
    "We uniformly sample contexts during training, a common way to perform domain randomization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "c_uniform = {'context_distribution':\n",
    "             UniformDistribution(dim=6,\n",
    "                              lower_bound_vector=np.array([0.0, 1.0, 2, 0.05, 0.05, 0.0]),\n",
    "                              upper_bound_vector=np.array([0.0, 3.0, 2, 0.05, 0.05, 0.0]))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "ray.shutdown()\n",
    "ray.init()\n",
    "uniform_solver = ppo.PPOTrainer(env=ContextualCliff, config={\n",
    "                                                    \"env_config\": c_uniform,\n",
    "                                                    \"framework\": \"torch\",  # config to pass to env class\n",
    "                                                })\n",
    "\n",
    "rews = []\n",
    "for eps in range(25):\n",
    "    res = uniform_solver.train()\n",
    "    if eps % 5 == 0:\n",
    "        print(eps, res['episode_reward_mean'])\n",
    "    rews += [res['episode_reward_mean']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plot_rollouts(*get_rollouts(uniform_solver,\n",
    "                           config={'context_distribution':\n",
    "                                    ConstantDistribution(dim=5,\n",
    "                                    constant_vector=np.array([0.0, 1.5, 2.0, 0.05, 0.05, 0.0]))}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plot_rollouts(*get_rollouts(uniform_solver,\n",
    "                           config={'context_distribution':\n",
    "                                    ConstantDistribution(dim=5,\n",
    "                                    constant_vector=np.array([0.0, 2.5, 2.0, 0.05, 0.05, 0.0]))}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "right_bound = np.random.normal(loc=2.5, scale=0.5, size=(N,))\n",
    "noise = np.ones((N,)) * 0.05\n",
    "\n",
    "context_particles = np.abs(np.vstack((left_bound, right_bound, pow, step_size, noise, drift)).T)\n",
    "context_distribution = ParticleDistribution(dim=6, particles=context_particles, n_particles=N)\n",
    "\n",
    "context_history_uniform = filter_context(uniform_solver,\n",
    "                                           context_distribution,\n",
    "                                           gt_obs_arr,\n",
    "                                           T,\n",
    "                                           N\n",
    "                                           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "HIST_BINS = np.linspace(1, 4, 80)\n",
    "ax.hist(context_history_uniform[0][:, 1], HIST_BINS, lw=1,\n",
    "        ec=\"blue\", fc=\"blue\", alpha=0.5)\n",
    "ax.hist(context_history_uniform[-1][:, 1], HIST_BINS, lw=1,\n",
    "        ec=\"red\", fc=\"red\", alpha=0.5)\n",
    "plt.axvline(x=2, alpha=0.3, color='black', linestyle='--')\n",
    "plt.legend(['ground truth: 2.0', 'prior', 'posterior'])\n",
    "ax.set_ylim(top=N / 5)\n",
    "fig.set_size_inches(12, 8)\n",
    "plt.title('solver trained in uniformly sampled context')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Importance sampling for context\n",
    "\n",
    "We do training - PF filtering update - training loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-14 15:57:05,331\tINFO services.py:1340 -- View the Ray dashboard at \u001B[1m\u001B[32mhttp://127.0.0.1:8265\u001B[39m\u001B[22m\n",
      "2022-02-14 15:57:07,635\tWARNING util.py:57 -- Install gputil for GPU system monitoring.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 -99.76200537262714\n",
      "[0.   2.   2.   0.05 0.05 0.  ]\n",
      "1 -99.41105112858652\n",
      "[0.   2.2  2.   0.05 0.05 0.  ]\n",
      "2 -98.18317576491216\n",
      "[0.   2.4  2.   0.05 0.05 0.  ]\n",
      "3 -87.46754835771316\n",
      "[0.   2.6  2.   0.05 0.05 0.  ]\n",
      "4 -77.2837027627055\n",
      "[0.   2.8  2.   0.05 0.05 0.  ]\n",
      "5 -75.5385437791193\n",
      "[0.   3.   2.   0.05 0.05 0.  ]\n",
      "6 -69.10061017438866\n",
      "[0.   3.2  2.   0.05 0.05 0.  ]\n",
      "7 -58.6658449707593\n",
      "[0.   3.4  2.   0.05 0.05 0.  ]\n",
      "8 -37.242462217478895\n",
      "[0.   3.6  2.   0.05 0.05 0.  ]\n",
      "9 -31.784324284554405\n",
      "[0.   3.8  2.   0.05 0.05 0.  ]\n",
      "10 -28.64796325083168\n",
      "[0.   4.   2.   0.05 0.05 0.  ]\n",
      "11 -24.61236093808337\n",
      "[0.   4.2  2.   0.05 0.05 0.  ]\n",
      "12 -23.401666954561087\n",
      "[0.   4.4  2.   0.05 0.05 0.  ]\n",
      "13 -13.558363910959429\n",
      "[0.   4.6  2.   0.05 0.05 0.  ]\n",
      "14 -11.174483153082623\n",
      "[0.   4.8  2.   0.05 0.05 0.  ]\n",
      "15 -25.60910890901097\n",
      "[0.   5.   2.   0.05 0.05 0.  ]\n",
      "16 -30.443297434663712\n",
      "[0.   5.2  2.   0.05 0.05 0.  ]\n",
      "17 -28.04832344331563\n",
      "[0.   5.4  2.   0.05 0.05 0.  ]\n",
      "18 -23.88609293371605\n",
      "[0.   5.6  2.   0.05 0.05 0.  ]\n",
      "19 -16.684441590843633\n",
      "[0.   5.8  2.   0.05 0.05 0.  ]\n",
      "20 -14.793687436296032\n",
      "[0.   6.   2.   0.05 0.05 0.  ]\n",
      "21 -15.167476971265597\n",
      "[0.   6.2  2.   0.05 0.05 0.  ]\n",
      "22 -15.555251145734935\n",
      "[0.   6.4  2.   0.05 0.05 0.  ]\n",
      "23 -14.867319805093462\n",
      "[0.   6.6  2.   0.05 0.05 0.  ]\n",
      "24 -17.09512605692735\n",
      "[0.   6.8  2.   0.05 0.05 0.  ]\n"
     ]
    }
   ],
   "source": [
    "rews = []\n",
    "c_mut = ConstantDistribution(dim=6,\n",
    "                                  constant_vector=np.array([0.0, 0.5, 2, 0.05, 0.05, 0.0]),\n",
    "                                     )\n",
    "mut_context_dist = {'context_distribution': c_mut}\n",
    "ray.shutdown()\n",
    "ray.init()\n",
    "imp_solver = ppo.PPOTrainer(env=ContextualCliff, config={\n",
    "                                                    \"env_config\": mut_context_dist,\n",
    "                                                    \"framework\": \"torch\",  # config to pass to env class\n",
    "                                                })\n",
    "for eps in range(25):\n",
    "    res = imp_solver.train()\n",
    "    print(eps, res['episode_reward_mean'])\n",
    "    rews += [res['episode_reward_mean']]\n",
    "    c_mut.update({'constant_vector': np.array([0.0, 2.0+eps/5, 2, 0.05, 0.05, 0.0])})\n",
    "    imp_solver.config['env_config']['context_distribution'] = c_mut\n",
    "    print(imp_solver.config['env_config']['context_distribution'].constant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_env_id': 'ContextualCliff',\n",
       " 'env_creator': <function ray.rllib.agents.trainer.Trainer._register_if_needed.<locals>.<lambda>(cfg)>,\n",
       " 'local_replay_buffer': None,\n",
       " '_experiment_id': 'abc276d335b34e37a74373ad532c6af0',\n",
       " 'config': {'num_workers': 2,\n",
       "  'num_envs_per_worker': 1,\n",
       "  'create_env_on_driver': False,\n",
       "  'rollout_fragment_length': 200,\n",
       "  'batch_mode': 'truncate_episodes',\n",
       "  'gamma': 0.99,\n",
       "  'lr': 5e-05,\n",
       "  'train_batch_size': 4000,\n",
       "  'model': {'_use_default_native_models': False,\n",
       "   '_disable_preprocessor_api': False,\n",
       "   'fcnet_hiddens': [256, 256],\n",
       "   'fcnet_activation': 'tanh',\n",
       "   'conv_filters': None,\n",
       "   'conv_activation': 'relu',\n",
       "   'post_fcnet_hiddens': [],\n",
       "   'post_fcnet_activation': 'relu',\n",
       "   'free_log_std': False,\n",
       "   'no_final_linear': False,\n",
       "   'vf_share_layers': False,\n",
       "   'use_lstm': False,\n",
       "   'max_seq_len': 20,\n",
       "   'lstm_cell_size': 256,\n",
       "   'lstm_use_prev_action': False,\n",
       "   'lstm_use_prev_reward': False,\n",
       "   '_time_major': False,\n",
       "   'use_attention': False,\n",
       "   'attention_num_transformer_units': 1,\n",
       "   'attention_dim': 64,\n",
       "   'attention_num_heads': 1,\n",
       "   'attention_head_dim': 32,\n",
       "   'attention_memory_inference': 50,\n",
       "   'attention_memory_training': 50,\n",
       "   'attention_position_wise_mlp_dim': 32,\n",
       "   'attention_init_gru_gate_bias': 2.0,\n",
       "   'attention_use_n_prev_actions': 0,\n",
       "   'attention_use_n_prev_rewards': 0,\n",
       "   'framestack': True,\n",
       "   'dim': 84,\n",
       "   'grayscale': False,\n",
       "   'zero_mean': True,\n",
       "   'custom_model': None,\n",
       "   'custom_model_config': {},\n",
       "   'custom_action_dist': None,\n",
       "   'custom_preprocessor': None,\n",
       "   'lstm_use_prev_action_reward': -1},\n",
       "  'optimizer': {},\n",
       "  'horizon': None,\n",
       "  'soft_horizon': False,\n",
       "  'no_done_at_end': False,\n",
       "  'env': 'ContextualCliff',\n",
       "  'observation_space': None,\n",
       "  'action_space': None,\n",
       "  'env_config': {'context_distribution': <utils.distributions.ConstantDistribution at 0x7fb54637c310>},\n",
       "  'remote_worker_envs': False,\n",
       "  'remote_env_batch_wait_ms': 0,\n",
       "  'env_task_fn': None,\n",
       "  'render_env': False,\n",
       "  'record_env': False,\n",
       "  'clip_rewards': None,\n",
       "  'normalize_actions': True,\n",
       "  'clip_actions': False,\n",
       "  'preprocessor_pref': 'deepmind',\n",
       "  'log_level': 'WARN',\n",
       "  'callbacks': ray.rllib.agents.callbacks.DefaultCallbacks,\n",
       "  'ignore_worker_failures': False,\n",
       "  'log_sys_usage': True,\n",
       "  'fake_sampler': False,\n",
       "  'framework': 'torch',\n",
       "  'eager_tracing': False,\n",
       "  'eager_max_retraces': 20,\n",
       "  'explore': True,\n",
       "  'exploration_config': {'type': 'StochasticSampling'},\n",
       "  'evaluation_interval': None,\n",
       "  'evaluation_num_episodes': 10,\n",
       "  'evaluation_parallel_to_training': False,\n",
       "  'in_evaluation': False,\n",
       "  'evaluation_config': {},\n",
       "  'evaluation_num_workers': 0,\n",
       "  'custom_eval_function': None,\n",
       "  'sample_async': False,\n",
       "  'sample_collector': ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector,\n",
       "  'observation_filter': 'NoFilter',\n",
       "  'synchronize_filters': True,\n",
       "  'tf_session_args': {'intra_op_parallelism_threads': 2,\n",
       "   'inter_op_parallelism_threads': 2,\n",
       "   'gpu_options': {'allow_growth': True},\n",
       "   'log_device_placement': False,\n",
       "   'device_count': {'CPU': 1},\n",
       "   'allow_soft_placement': True},\n",
       "  'local_tf_session_args': {'intra_op_parallelism_threads': 8,\n",
       "   'inter_op_parallelism_threads': 8},\n",
       "  'compress_observations': False,\n",
       "  'collect_metrics_timeout': 180,\n",
       "  'metrics_smoothing_episodes': 100,\n",
       "  'min_iter_time_s': 0,\n",
       "  'timesteps_per_iteration': 0,\n",
       "  'seed': None,\n",
       "  'extra_python_environs_for_driver': {},\n",
       "  'extra_python_environs_for_worker': {},\n",
       "  'num_gpus': 0,\n",
       "  '_fake_gpus': False,\n",
       "  'num_cpus_per_worker': 1,\n",
       "  'num_gpus_per_worker': 0,\n",
       "  'custom_resources_per_worker': {},\n",
       "  'num_cpus_for_driver': 1,\n",
       "  'placement_strategy': 'PACK',\n",
       "  'input': 'sampler',\n",
       "  'input_config': {},\n",
       "  'actions_in_input_normalized': False,\n",
       "  'input_evaluation': ['is', 'wis'],\n",
       "  'postprocess_inputs': False,\n",
       "  'shuffle_buffer_size': 0,\n",
       "  'output': None,\n",
       "  'output_compress_columns': ['obs', 'new_obs'],\n",
       "  'output_max_file_size': 67108864,\n",
       "  'multiagent': {'policies': {'default_policy': PolicySpec(policy_class=<class 'ray.rllib.agents.ppo.ppo_torch_policy.PPOTorchPolicy'>, observation_space=None, action_space=None, config={})},\n",
       "   'policy_map_capacity': 100,\n",
       "   'policy_map_cache': None,\n",
       "   'policy_mapping_fn': None,\n",
       "   'policies_to_train': None,\n",
       "   'observation_fn': None,\n",
       "   'replay_mode': 'independent',\n",
       "   'count_steps_by': 'env_steps'},\n",
       "  'logger_config': None,\n",
       "  '_tf_policy_handles_more_than_one_loss': False,\n",
       "  '_disable_preprocessor_api': False,\n",
       "  'simple_optimizer': False,\n",
       "  'monitor': -1,\n",
       "  'use_critic': True,\n",
       "  'use_gae': True,\n",
       "  'lambda': 1.0,\n",
       "  'kl_coeff': 0.2,\n",
       "  'sgd_minibatch_size': 128,\n",
       "  'shuffle_sequences': True,\n",
       "  'num_sgd_iter': 30,\n",
       "  'lr_schedule': None,\n",
       "  'vf_loss_coeff': 1.0,\n",
       "  'entropy_coeff': 0.0,\n",
       "  'entropy_coeff_schedule': None,\n",
       "  'clip_param': 0.3,\n",
       "  'vf_clip_param': 10.0,\n",
       "  'grad_clip': None,\n",
       "  'kl_target': 0.01,\n",
       "  'vf_share_layers': -1},\n",
       " '_result_logger': <ray.tune.logger.UnifiedLogger at 0x7fb520c84c10>,\n",
       " '_logdir': '/Users/mingweima/ray_results/PPO_ContextualCliff_2022-02-14_15-46-58jtkud4w8',\n",
       " '_stdout_context': None,\n",
       " '_stdout_fp': None,\n",
       " '_stdout_stream': None,\n",
       " '_stderr_context': None,\n",
       " '_stderr_fp': None,\n",
       " '_stderr_stream': None,\n",
       " '_stderr_logging_handler': None,\n",
       " '_iteration': 19,\n",
       " '_time_total': 142.62396216392517,\n",
       " '_timesteps_total': 0,\n",
       " '_episodes_total': 2232,\n",
       " '_time_since_restore': 142.62396216392517,\n",
       " '_timesteps_since_restore': 0,\n",
       " '_iterations_since_restore': 19,\n",
       " '_restored': False,\n",
       " '_trial_info': None,\n",
       " '_stdout_file': None,\n",
       " '_stderr_file': None,\n",
       " '_local_ip': '127.0.0.1',\n",
       " '_allow_unknown_configs': False,\n",
       " 'callbacks': <ray.rllib.agents.callbacks.DefaultCallbacks at 0x7fb54637c990>,\n",
       " 'workers': <ray.rllib.evaluation.worker_set.WorkerSet at 0x7fb54637c390>,\n",
       " 'train_exec_impl': LocalIterator[ParallelIterator[from_actors[shards=2]].batch_across_shards().for_each().for_each().for_each().combine().for_each().for_each().for_each().for_each().filter().filter().for_each().for_each()],\n",
       " '_policy_class': ray.rllib.agents.ppo.ppo_torch_policy.PPOTorchPolicy,\n",
       " 'execution_plan': <function ray.rllib.agents.ppo.ppo.execution_plan(workers: ray.rllib.evaluation.worker_set.WorkerSet, config: dict, **kwargs) -> ray.util.iter.LocalIterator[dict]>,\n",
       " 'evaluation_workers': None,\n",
       " 'evaluation_metrics': {},\n",
       " '_monitor': <UtilMonitor(Thread-25, started daemon 22375186432)>,\n",
       " 'remote_checkpoint_dir': None,\n",
       " 'sync_function_tpl': None,\n",
       " 'storage_client': None}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imp_solver.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}